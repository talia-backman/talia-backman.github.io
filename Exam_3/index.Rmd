---
title: "BACKMAN_Skills_Test_3"
author: "Backman"
date: "4/11/2020"
output: html_document
---

```{r, message=FALSE}
#load libraries
library(tidyverse)
library(modelr)
library(GGally)
library(lindia)
library(skimr)
library(patchwork)
library(caret)
```

```{r}
#load mtcars dataset
data("mtcars")
```

```{r, message=FALSE}
#1. Do an analysis of mtcars dataset
#get to know your data
mtcars %>% ggpairs()
```

Do a ggpair analysis to see where correlations may be.  Looks like mpg has a correlation with wt and cyl.  

```{r}
#test different models
mod1 <- lm(data=mtcars, formula = mpg ~ wt)
mod2 <- lm(data=mtcars, formula = mpg ~ wt + cyl)
mod3 <- lm(data=mtcars, formula = mpg ~ wt * cyl)
```
```{r}
#look at summaries for the models and look at intercepts and pvalues
summary(mod1)
summary(mod2) 
summary(mod3)
```

All pvalues look significant, they all seem to be good models so we will dig deeper into these models.

```{r, message=FALSE}
#look at model diagnostics
gg_diagnose(mod1)
gg_diagnose(mod2)
gg_diagnose(mod3)
```

```{r}
#compare models
anova(mod1, mod2) 
anova(mod1, mod3)
anova(mod2, mod3)
```

This shows that all the models are different from eachother because they all have significant pvalues.

```{r}
#which has the best fit line?
mod1mse <- mean(residuals(mod1)^2)
mod2mse <- mean(residuals(mod2)^2)
mod3mse <- mean(residuals(mod3)^2)

mod1mse ; mod2mse ; mod3mse
```

mod3mse has the best fit line, so we will use that model.

```{r}
#evaluate predictions
df_mod3 <- add_predictions(mtcars,mod3) 
df_mod3
formula(df_mod3)
```
```{r}
allmods <- gather_predictions(mtcars, mod1,mod2,mod3) 
allmods
skim(allmods)
names(allmods)
```

```{r}
#compare predictions to reality
p1.new <- ggplot(df_mod3,aes(x=wt,color=factor(cyl))) +
  geom_point(aes(y=mpg),alpha=.5,size=2) +
  geom_point(aes(y=pred),color="Black") + theme_bw()
p1.new
```

```{r}
#look at predictions for the models
ggplot(allmods,aes(x=wt,color=factor(cyl))) +
  geom_point(aes(y=mpg),alpha=.25) +
  geom_point(aes(y=pred),color="Black") +
  facet_wrap(~model) +
  theme_bw()

#Looks like model 2 and 3 are best for this data.  

set.seed(123)
set <- caret::createDataPartition(mtcars$mpg)
set <- set$Resample1

train <- mtcars[set,]
test <- mtcars[-set,]

formula(mod3)
trainedmodel <- lm(data=train, formula = formula(mod3))

add_predictions(test,mod3) %>%
  ggplot(aes(x=wt,color=factor(cyl))) +
  geom_point(aes(y=mpg)) + geom_smooth(method = "lm",aes(y=pred))

testedresiduals <- (test$pred - test$mpg)

df2 <- gather_predictions(mtcars, mod3,trainedmodel)
  
ggplot(df2, aes(x=disp,color=factor(cyl))) +
  geom_point(aes(y=mpg),alpha=.2) +
  geom_smooth(method = "lm",aes(linetype=model,y=pred)) + theme_bw()

```

From the models, the third one gave the best mathematical guess as to how mpg can be predicted by cylinder and displacement.  