---
title: "BACKMAN Skills Test 3"
output: html_document
---
<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>

<style>
div.gray { background-color:#7e8687; border-radius: 5px; padding: 20px;}
</style>
<div class = "gray">



<style>
div.blue { background-color:#9dc9d1; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

### **Load Libraries**

```{r, message=FALSE}
library(tidyverse)
library(modelr)
library(GGally)
library(lindia)
library(skimr)
library(patchwork)
library(caret)
```

### **Load dataset**

```{r}
data("mtcars")
```

### **Get an overview of mtcars dataset and possible correlations**

```{r, message=FALSE}
mtcars %>% ggpairs()
```

#### Looks like mpg has some correlation with wt and cyl.

### **Test different models and look at their pvalues**
#### Reminder: pvalue<0.05 is significant. Anything over that value shouldn't be used in a model.

```{r}
mod1 <- lm(data=mtcars, formula = mpg ~ wt)
mod2 <- lm(data=mtcars, formula = mpg ~ wt + cyl)
mod3 <- lm(data=mtcars, formula = mpg ~ wt * cyl)
```
```{r}
summary(mod1) ; summary(mod2) ; summary(mod3)
```

#### All pvalues look significant, they all seem to be good models.

### **Compare our current models to see if they differ from eachother**

```{r,message=FALSE}
anova(mod1, mod2) ; anova(mod1, mod3) ; anova(mod2, mod3)
```

#### All the models are different from eachother.  We know this because they all have significant pvalues (<0.05).

### **Best fit line**
#### Because nothing has been conclusively leading us to a certain model, we will see which has the best fit line.

```{r}
mod1mse <- mean(residuals(mod1)^2)
mod2mse <- mean(residuals(mod2)^2)
mod3mse <- mean(residuals(mod3)^2)

mod1mse ; mod2mse ; mod3mse
```

#### The lowest number shows the best fit line model.  mod3mse has the best fit line, so we will use that model.

### **Evaluating predictions**

```{r, message=FALSE}
df_mod3 <- add_predictions(mtcars,mod3) 
formula(df_mod3)
```
```{r, message=FALSE}
allmods <- gather_predictions(mtcars, mod1,mod2,mod3) 
head(allmods)
```

### **Look at predictions for all models**

```{r}
ggplot(allmods,aes(x=wt,color=factor(cyl))) +
  geom_point(aes(y=mpg),alpha=.25) +
  geom_point(aes(y=pred),color="Black") +
  facet_wrap(~model) +
  theme_bw()
```

#### Looks like mod2 or mod3 will be best for our data.  I will use mod3. 

### **Compare predictions to reality for mod3**

```{r}
p1.new <- ggplot(df_mod3,aes(x=wt,color=factor(cyl))) +
  geom_point(aes(y=mpg),alpha=.5,size=2) +
  geom_point(aes(y=pred),color="Black") + theme_bw()
p1.new
```

#### Everything looks good.  

### **Test mod3 against a trained model of predictions**

```{r, message=FALSE, warning=FALSE}

set.seed(123)
set <- caret::createDataPartition(mtcars$mpg)
set <- set$Resample1

train <- mtcars[set,]
test <- mtcars[-set,]

trainedmodel <- lm(data=train, formula = formula(mod3))

testedresiduals <- (test$pred - test$mpg)

df2 <- gather_predictions(mtcars, mod3,trainedmodel)
  
ggplot(df2, aes(x=disp,color=factor(cyl))) +
  geom_point(aes(y=mpg),alpha=.2) +
  geom_smooth(method = "lm",aes(linetype=model,y=pred)) + theme_bw()

```

From the models, the third one gave the best mathematical guess as to how mpg can be predicted by cylinder and displacement. The linear models seem to be pretty close.  I would say this is a good model based off of the graphs and pvalues.  
